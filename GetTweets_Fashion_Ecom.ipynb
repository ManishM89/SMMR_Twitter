{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ####input your credentials here\n",
    "# consumer_key='WSThrm3ccgtbOqTxT8NKZo5Eq'\n",
    "# consumer_secret='itw42H5tqBQ3NbI3UowE5BuSGQfZa19hoksmAvSzWdAhUbeMHz'\n",
    "# access_token='899497448116166656-oEIbWOGssskDzTr3Q3BzFfxNflYjuYI'\n",
    "# access_token_secret='SrXwtmZ2KlKxnAo24bKm8ae9qfQ1s6jp1AClE1snw6vrP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####input your credentials here\n",
    "consumer_key='5iVfcttFRSKW4FKH2tSQIPD5i'\n",
    "consumer_secret='LLd8XyqdhRAiiU9fLOLJ5hGu2GkGs3JWZgKloAhFGhmbP2Pg3x'\n",
    "access_token='64227694-gsp3mTy7AKW9yplknfmBNpYz0Cgdg4n9DW34q4R2a'\n",
    "access_token_secret='k47tIWaWQ3454nODb4iBjzQu9mcor2D2dk8izKGfd8Epc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "# api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tweets = []\n",
    "# for tweet in tweepy.Cursor(api.search,q=\"voonik\",count=10000,\n",
    "#                            lang=\"en\",\n",
    "#                            since=\"2017-08-01\").items():\n",
    "#     Tweets.append(tweet)\n",
    "    \n",
    "# ################################################    \n",
    "# csvFile = open('Voonik.csv', 'w')\n",
    "# csvWriter = csv.writer(csvFile)\n",
    "# for tweet in Tweets:\n",
    "#     if tweet.author.screen_name.lower().find(\"voonik\") == -1:\n",
    "#         csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handleNames = [\"myntra\", \"jabong\", \"voonik\", \"ajio\", \"koovs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for handleName in handleNames:\n",
    "    Tweets = []\n",
    "    for tweet in tweepy.Cursor(api.search,q=handleName,count=10000,\n",
    "                               lang=\"en\",\n",
    "                               since=\"2017-08-01\").items():\n",
    "        Tweets.append(tweet)\n",
    "\n",
    "    ################################################    \n",
    "    csvFile = open(handleName + '.csv', 'w')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    for tweet in Tweets:\n",
    "        if tweet.author.screen_name.lower().find(handleName) == -1:\n",
    "            csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ###Preprocess tweets\n",
    "# def processTweet2(tweet):\n",
    "#     # process the tweets\n",
    "\n",
    "#     #Convert to lower case\n",
    "#     tweet = tweet.lower()\n",
    "#     #Convert www.* or https?://* to URL\n",
    "#     tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "#     #Convert @username to AT_USER\n",
    "#     tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "#     #Remove additional white spaces\n",
    "#     tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "#     #Replace #word with word\n",
    "#     tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "#     #trim\n",
    "#     tweet = tweet.strip('\\'\"')\n",
    "#     return tweet    \n",
    "\n",
    "# ###get stopword list\n",
    "# def getStopWordList(stopWordListFileName):\n",
    "#     #read the stopwords file and build a list\n",
    "#     stopWords = []\n",
    "#     stopWords.append('AT_USER')\n",
    "#     stopWords.append('URL')\n",
    "\n",
    "#     fp = open(stopWordListFileName, 'r')\n",
    "#     line = fp.readline()\n",
    "#     while line:\n",
    "#         word = line.strip()\n",
    "#         stopWords.append(word)\n",
    "#         line = fp.readline()\n",
    "#     fp.close()\n",
    "#     return stopWords\n",
    "\n",
    "# stopWords = []\n",
    "\n",
    "# st = open('stopwords.txt', 'r')\n",
    "# stopWords = getStopWordList('stopwords.txt')\n",
    "\n",
    "\n",
    "# def replaceTwoOrMore(s):\n",
    "#     #look for 2 or more repetitions of character and replace with the character itself\n",
    "#     pattern = re.compile(r\"(.)\\1{1,}\", re.DOTALL)\n",
    "#     return pattern.sub(r\"\\1\\1\", s)\n",
    "# #end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
